# Loan Fraud Detection
<p align="center">
<img src="https://plus.unsplash.com/premium_photo-1661672185492-d07613b7600f?w=500&auto=format&fit=crop&q=60&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxzZWFyY2h8NXx8bG9hbiUyMGZyYXVkfGVufDB8fDB8fHww" style="width: 40%;">
</p>

## Table of Contents 
<table>
<tr>
<td>
<a href="#introduction">Introduction</a><br>
<a href="#data">Data</a><br>
<a href="#data-preprocessing">Data Preprocessing and Feature Engineering</a><br>
<a href="#sampling">Sampling Strategy</a><br>
<a href="#model-training">LightGBM Model</a><br>
<a href="#evaluation">Evaluation</a><br>
<a href="#next-steps">Next Steps</a><br>
<a href="#conclusion">Conclusion</a>
</td>
</tr>
</table>

## Introduction
<a name="introduction"></a>

In this project, I developed a machine learning model for detecting fraudulent loan applications. Early detection of fraudulent activity allows financial institutions to mitigate risks, prevent financial losses, and ensure the integrity of their lending processes. The model leverages a combination of applicant information, behavioral data, and derived features to detect potentially fraudulent applications.

A significant challenge in fraud detection is achieving high precision while dealing with highly imbalanced datasets, where fraudulent cases represent only a small fraction of the total samples. In the context of loan fraud detection, minimizing false negatives is particularly important, as this can result in legitimate customers being denied credit. Consequently, it is standard business practice to calibrate models to operate below a predetermined False Positive Rate (FPR) and use the True Positive Rate (TPR) as the performance metric. For this project, I used four evaluation metrics: TPR at 5% FPR, TPR at 1% FPR, Receiver Operating Characteristic (ROC) and Area Under the Curve (AUC) score, and a fairness metric called predictive equality.

## Data
<a name="data"></a>
**Paper:** [Turning the Tables: Biased, Imbalanced, Dynamic Tabular Datasets for ML Evaluation](https://arxiv.org/abs/2211.13358)  
**GitHub:** [Bank Account Fraud](https://github.com/feedzai/bank-account-fraud)

The Bank Account Fraud (BAF) suite of datasets, published at NeurIPS 2022, includes a collection of tabular datasets specifically designed for evaluating machine learning methods in the context of fraud detection. Each dataset is synthetically generated by utilizing real bank application data processed through a CTGAN (Conditional Generative Adversarial Network) to ensure the privacy and anonymity of applicants. 

The base dataset used for this project, which is intended to closely represent the original bank data, is comprised of 1 million samples, each with 30 features that reflect 8 months of synthetic bank application data. The features were carefully selected by the authors for their predictive power in predicting fraudulent activity. Furthermore, the authors recommend using the first 6 months of data for training the model and the last 2 months for testing its performance.

<p align="center">
<img src="https://github.com/MattPickard/Data-Science-Portfolio/blob/main/Images/fraud_distribution.png?raw=true" style="width: 40%;">
</p>
<p align="center"><i>The dataset exhibits a significant class imbalance, with only 1.10% of samples labeled fraudulent.</i></p>

## Preprocessing and Feature Engineering
<a name="data-preprocessing"></a>
**Code:** [**Preprocessing**](https://github.com/MattPickard/Data-Science-Portfolio/blob/main/Loan%20Fraud%20Detection%20Project/preprocess.ipynb)

The following steps were taken to prepare the data for training the model:

1. **Feature Removal**: The `device_fraud_count` feature was removed because it contained no positive examples in this dataset, which would not contribute to the model's learning.
2. **Data Splitting**: The dataset was divided into training and testing sets. The training set includes data from months 0 to 5, while the testing set includes data from months 6 to 7. This split allows for evaluating the model's performance on unseen data.
    - After the split, the training set contained **794,989 samples**, and the testing set contained **205,010 samples**.
3. **Feature Engineering**: An `income-to-credit-limit` ratio feature was created to better understand the relationship between an applicant's income and their proposed credit limit.
4. **Robust Scaling**: Robust scaling was applied to numerical features to scale them appropriately while effectively handling outliers.
5. **Log Scaling**: Log scaling was applied to the `days_since_request`, `zip_count_4w`, and `proposed_credit_limit` features to normalize their skewed distributions. (Refer to the Q-Q plots shown below for a visual representation of their skewed distributions.)
6. **Encoding Categorical Features**: One-hot encoding was performed on categorical features. This approach outperformed ordinal encoding, perhaps due to the small number of categories.
7. **Memory Optimization**: Numerical columns were downcasted to more efficient data types to optimize memory usage.
---
<p align="center">
<img src="https://github.com/MattPickard/Data-Science-Portfolio/blob/main/Images/q-q_plots.png?raw=true">
</p>
<p align="center"><i>Q-Q plots are used to compare the distribution to a theoretical normal distribution. The closer the points are to the line, the more normal the distribution.</i></p>

## Sampling Strategy
<a name="sampling"></a>
**Code:** [**Sampling**](https://github.com/MattPickard/Data-Science-Portfolio/blob/main/Loan%20Fraud%20Detection%20Project/sampling.ipynb)

To tackle the significant class imbalance in the dataset, I employed a mixed sampling strategy of random undersampling and the Synthetic Minority Over-sampling Technique for Nominal and Continuous Features (SMOTENC) to construct a balanced training set. This mixed approach proved to be more effective than simply using LightGBM's class weight training and simple random undersampling. 

After applying the sampling techniques, the training set, which consists of 57,057 samples, was composed as follows:

- **Real Fraudulent Samples:** Representing 1/12 of the training set
- **Synthetic Fraudulent Samples:** Created using SMOTENC, accounting for 5/12 of the training set
- **Real Non-Fraudulent Samples:** Selected through random undersampling to achieve a balanced class distribution

To maximize the real fraudulent class sample representation within the training set, the validation set was created using synthetic positive samples created using SMOTENC. While this may lead to an overly optimistic assessment of model performance on the validation set, it still provides valuable early stopping feedback to mitigate overfitting during the training process.

## LightGBM Model
<a name="model-training"></a>
**Code:** [**LightGBM Model**](https://github.com/MattPickard/Data-Science-Portfolio/blob/main/Loan%20Fraud%20Detection%20Project/lightgbm_model.ipynb)

LightGBM is a powerful gradient boosting framework that utilizes tree-based learning algorithms. I also experimented with CatBoost, another gradient boosting framework, but I found that LightGBM yielded slightly better performance, particularly after implementing a mixed sampling strategy.

To optimize the model's performance, I employed Optuna for hyperparameter tuning. This process helped identify the optimal set of hyperparameters aimed at maximizing the ROC AUC score. The final configuration for training the model is as follows:

- **Objective**: "binary"
- **Metric**: "AUC"
- **Num_leaves**: 230
- **Max_depth**: 25
- **Learning_rate**: 0.071
- **Feature_fraction**: 0.254

After training, in-built feature importance metrics can be called to see which features are most influential in the model's predictions. Below is a list of the top 10 features ranked by their importance. The complete list can be found in the code.

| Rank | Feature | Importance |
|------|--------------------------|------------|
| 1 | velocity_4w | 1937 |
| 2 | days_since_request | 1919 |
| 3 | zip_count_4w | 1638 |
| 4 | velocity_24h | 1542 |
| 5 | velocity_6h | 1531 |
| 6 | name_email_similarity | 1491 |
| 7 | intended_balcon_amount | 1343 |
| 8 | session_length_in_minutes| 1332 |
| 9 | credit_risk_score | 1300 |
| 10 | bank_branch_count_8w | 1174 |

## Evaluation
<a name="evaluation"></a>
**Code:** [**Evaluation**](https://github.com/MattPickard/Data-Science-Portfolio/blob/main/Loan%20Fraud%20Detection%20Project/evaluation.ipynb)

The model was evaluated using the following metrics: 

### 1. ROC Curve and AUC Score

<img src="https://github.com/MattPickard/Data-Science-Portfolio/blob/main/Images/roc_curve.png?raw=true" style="width: 50%;">

**ROC AUC Score:** 0.890

The ROC curve displayed above illustrates the trade-off between the True Positive Rate (TPR) and the False Positive Rate (FPR). The ROC curve is typically paired with the AUC score, which measures the classifier's ability to distinguish between positive and negative classes by calculating the area under the ROC curve. An AUC score of 0.5 indicates performance equivalent to random guessing, whereas a score of 1.0 signifies a perfect classifier.

---
### 2. True Positive Rate at 5% FPR:

**Global #1 Ranked Model from Academic Literature According to paperswithcode.com:** 54.3% ([Paper Link](https://arxiv.org/abs/2401.05240))  
**This Model:** 53.93% 

Due to the imbalanced nature of the dataset, it is important to understand that accuracy is not an appropriate metric for evaluating the model's performance. For example, in a dataset where only around 1% of transactions are fraudulent, a model that predicts every transaction as non-fraudulent would achieve an accuracy of 99% but with 0% TPR. Instead, we evaluate the TPR at a set FPR as our primary evaluation metric. Setting a desired FPR allows for a bank to choose a threshold that best balances fraud detection with ensuring loan officers are not overburdened with false positives. TPR at a 5% FPR is suggested as the primary performance metric in the original BAF paper. 

To have a model maintain a specified FPR for its predictions, the model's probability threshold for making predictions can be adjusted. While models usually use a threshold of 0.5, this can be adjusted to change the behavior of the model into being more or less strict with its predictions.

---
### 3. True Positive Rate at 1% FPR:

**Global #1 Ranked Model from Academic Literature According to paperswithcode.com:** 25.2% ([Paper Link](https://arxiv.org/abs/2408.12989))  
**This Model:** 25.57%

Banks may also be interested in the model's TPR at 1% FPR, as it reduces the likelihood of legitimate transactions being incorrectly flagged as fraudulent. This approach identifies fewer fraudulent cases, but it enhances customer trust and reduces the resources required for investigating false positives.

---
### 4. Predictive Equality:

**Model's Predictive Equality at 5% FPR:** 99.49%  
**Model's Predictive Equality at 1% FPR:** 99.71%

The authors of the BAF paper also proposed a fairness metric known as the predictive equality score. This score assesses the difference in 
FPR between specific groups: applicants aged over 50 and those under 50. A predictive equality score of 100% signifies that there is perfect equality in FPR between these two groups. Implementing such metrics can be useful for identifying model bias and ensuring compliance with regulatory standards. The BAF suite provides several biased datasets that can be utilized to test techniques aimed at reducing bias. However, this project used the base dataset, which was not specifically engineered to be biased.

## Next Steps
<a name="next-steps"></a>

### Implementation
- Build a real-time prediction pipeline incorporating request queuing to effectively manage high-traffic situations.
- Utilize SHAP (SHapley Additive exPlanations) values to enhance the transparency and interpretability of model predictions.
- Design a user-friendly dashboard for loan officers, enabling them to interpret and understand the model's predictions.

### Model Robustness
- Perform adversarial testing to assess the model's ability to withstand common fraud evasion techniques.
- Expand the feature set to include new and emerging fraud patterns and techniques.

### Business Integration
- Perform cost-benefit analyses at different False Positive Rate thresholds to optimize the model's business value.
- Calculate and track ROI metrics, including cost savings from prevented fraud and operational efficiency gains.

## Conclusion
<a name="conclusion"></a>

This project demonstrates the development of a loan fraud detection model that achieves performance on par with academic research. These results were achieved through careful feature engineering, a mixed sampling strategy to address class imbalance, and optimized LightGBM implementation. Models like this are highly useful in financial sectors where minimizing false positives is critical, such as in the case of loan fraud detection. By reducing the number of legitimate loan applications incorrectly flagged as fraudulent, the model positively impacts customer experience by maintaining trust and satisfaction. From a business perspective, it lowers operational costs associated with investigating false alarms and ensures efficient allocation of resources toward genuine fraud cases. This balance is essential for financial institutions to effectively combat fraud while maintaining a positive customer experience. If you have any comments or questions, please feel free to reach out!
