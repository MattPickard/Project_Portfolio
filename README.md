# Project Portfolio
This repository showcases a selection of my data science and machine learning projects. I hope you find them useful and interesting!  

## **Agentic Investing with LLM Agents and MCP ([Link](https://github.com/MattPickard/Project_Portfolio/tree/main/Agentic_Investing_Project))**

###### **Tags:** OpenAI Agents SDK, Model Context Protocol (MCP), AWS, Docker, Power BI Dashboard

<table style="margin: auto;">
    <tr>
        <td style="text-align: center;">
            <a href="https://github.com/MattPickard/Project_Portfolio/tree/main/Agentic_Investing_Project">
                <img src="https://www.livemint.com/lm-img/img/2025/03/31/600x338/g1c49305ef246b25d62f_1743440565533_1743440565716.jpg" style="height: 150px; width: auto;"/>
            </a>
        </td>
        <td style="text-align: center;">
            <a href="https://github.com/MattPickard/Project_Portfolio/tree/main/Agentic_Investing_Project">
                <img src="https://raw.githubusercontent.com/MattPickard/Project_Portfolio/refs/heads/main/Images/mcp_inspector.png" style="height: 150px; width: auto;"/>
            </a>
        </td>
        <td style="text-align: center;">
            <a href="https://github.com/MattPickard/Project_Portfolio/tree/main/Agentic_Investing_Project">
                <img src="https://raw.githubusercontent.com/MattPickard/Project_Portfolio/refs/heads/main/Images/powerbi_dashboard.png" style="height: 150px; width: auto;"/>
            </a>
        </td>
    </tr>
</table>

This project creates a comprehensive platform where Large Language Model (LLM) agents are developed and evaluated within a simulated stock market environment. It integrates a simplified stock market simulation, an MCP server hosted on AWS (using Docker, EC2, and S3) to expose simulation functions as tools, and three types of LLM agents (Interactive, Human-in-the-Loop, and Autonomous) built with the OpenAI Agents SDK. These agents, powered by OpenAI's Agents SDK and gpt-4o-mini, interact with the simulation via the MCP server's tools to manage a portfolio, with their performance and actions tracked and visualized using a Power BI dashboard, ultimately creating a robust testbed for agentic AI development.

## **NASA Turbofan Engine Sensor Data Prognostics Models ([Link](https://github.com/MattPickard/Project_Portfolio/tree/main/Turbofan_Engine_Prognostics_Project))**

###### **Tags:** Convolutional Neural Networks (CNNs), CatBoost, Engine Prognostics, TensorFlow/Keras, Feature Extraction

<table style="margin: auto;">
    <tr>
        <td style="text-align: center;">
            <a href="https://github.com/MattPickard/Project_Portfolio/tree/main/Turbofan_Engine_Prognostics_Project">
                <img src="https://plus.unsplash.com/premium_photo-1679758629409-83446005843c?w=500&auto=format&fit=crop&q=60&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxzZWFyY2h8MXx8YWlycGxhbmUlMjB0dXJib2ZhbiUyMGVuZ2luZXxlbnwwfHwwfHx8MA%3D%3D" style="height: 150px; width: auto;"/>
            </a>
        </td>
        <td style="text-align: center;">
            <a href="https://github.com/MattPickard/Project_Portfolio/tree/main/Turbofan_Engine_Prognostics_Project">
                <img src="https://raw.githubusercontent.com/MattPickard/Project_Portfolio/refs/heads/main/Images/rul_15.png" style="height: 150px; width: auto;"/>
            </a>
        </td>
        <td style="text-align: center;">
            <a href="https://github.com/MattPickard/Project_Portfolio/tree/main/Turbofan_Engine_Prognostics_Project">
                <img src="https://raw.githubusercontent.com/MattPickard/Project_Portfolio/refs/heads/main/Images/hs_15.png" style="height: 150px; width: auto;"/>
            </a>
        </td>
    </tr>
</table>

This project utilizes a NASA run-to-failure dataset to develop hybrid models that predict the Remaining Useful Life (RUL) and health status of turbofan engines. By integrating one-dimensional convolutional neural networks with CatBoost models, this approach effectively captures the temporal patterns present in sensor data. The resulting predictions serve as valuable tools for engineers, enabling proactive maintenance scheduling and monitoring engine health.

## **Querying my Grandfather's Memoir with RAG ([Link](https://github.com/MattPickard/Project_Portfolio/tree/main/Memoir_Rag_Project))**

###### **Tags:** Retrieval-Augmented Generation (RAG), Natural Language Processing (NLP), Reranking, LangChain, OpenAI API

<table style="margin: auto;">
    <tr>
        <td style="text-align: center;">
            <a href="https://github.com/MattPickard/Project_Portfolio/tree/main/Memoir_RAG_Project">
                <img src="https://github.com/MattPickard/Project_Portfolio/blob/main/Images/family_photo.jpg" style="height: 150px; width: auto;"/>
            </a>
        </td>
        <td style="text-align: center;">
            <a href="https://github.com/MattPickard/Project_Portfolio/tree/main/Memoir_RAG_Project">
                <img src="https://github.com/MattPickard/Project_Portfolio/blob/main/Images/success_rates.png" style="height: 150px; width: auto;"/>
            </a>
        </td>
        <td style="text-align: center;">
            <a href="https://github.com/MattPickard/Project_Portfolio/tree/main/Memoir_RAG_Project">
                <img src="https://github.com/MattPickard/Project_Portfolio/blob/main/Images/evaluation_breakdown.png" style="height: 150px; width: auto;"/>
            </a>
        </td>
    </tr>
</table>

In this project I demonstrate the application of various Retrieval-Augmented Generation (RAG) techniques, creating an ensemble pipeline that answers questions about my grandfather's memoir. The techniques implimented are often used in the natural language processing and information retrieval applications. The findings reveal how enhancements like reranking and context enrichment through an ensemble approach can significantly improve retrieval success rates.

## **Loan Fraud Detection ([Link](https://github.com/MattPickard/Project_Portfolio/tree/main/Loan_Fraud_Detection_Project))**

###### **Tags:** Feature Engineering, Imbalanced Learning, LightGBM, Optuna Hyperparameter Tuning, Fraud Detection

<table style="margin: auto;">
    <tr>
        <td style="text-align: center;">
            <a href="https://github.com/MattPickard/Project_Portfolio/tree/main/Loan_Fraud_Detection_Project">
                <img src="https://plus.unsplash.com/premium_photo-1661672185492-d07613b7600f?w=500&auto=format&fit=crop&q=60&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxzZWFyY2h8NXx8bG9hbiUyMGZyYXVkfGVufDB8fDB8fHww" style="height: 150px; width: auto;"/>
            </a>
        </td>
        <td style="text-align: center;">
            <a href="https://github.com/MattPickard/Project_Portfolio/tree/main/Loan_Fraud_Detection_Project">
                <img src="https://raw.githubusercontent.com/MattPickard/Project_Portfolio/refs/heads/main/Images/roc_curve.png" style="height: 150px; width: auto;"/>
            </a>
        </td>
        <td style="text-align: center;">
            <a href="https://github.com/MattPickard/Project_Portfolio/tree/main/Loan_Fraud_Detection_Project">
                <img src="https://raw.githubusercontent.com/MattPickard/Project_Portfolio/refs/heads/main/Images/fraud_distribution.png" style="height: 150px; width: auto;"/>
            </a>
        </td>
    </tr>
</table>

This project provides a practical machine learning framework for detecting fraudulent loan applications while minimizing false positives that could impact legitimate customers. The solution employs a mixed sampling strategy combining SMOTENC and random undersampling to address class imbalance, along with comprehensive feature engineering including log scaling, robust scaling, and one-hot encoding. The LightGBM model, optimized through Optuna hyperparameter tuning, achieves performance on par with academic research, with velocity-based features and temporal metrics emerging as the most influential predictors. 

## **Adapting Neural Networks: Fine-Tuning for Digit Recognition ([Link](https://github.com/MattPickard/Project_Portfolio/tree/main/Fine-Tuning_for_Digit_Recognition_Project))**

###### **Tags:** Computer Vision, Fine-Tuning, Convolutional Neural Networks (CNNs), Low-Rank Adaptation (LoRA), TensorFlow/Keras

<table style="margin: auto;">
    <tr>
        <td style="text-align: center;">
            <a href="https://github.com/MattPickard/Project_Portfolio/tree/main/Fine-Tuning_for_Digit_Recognition_Project">
                <img src="https://awaywithideas.com/assets/images/2020/10/mnist_extended_4_0.png" style="height: 150px; width: auto;"/>
            </a>
        </td>
        <td style="text-align: center;">
            <a href="https://github.com/MattPickard/Project_Portfolio/tree/main/Fine-Tuning_for_Digit_Recognition_Project">
                <img src="https://github.com/MattPickard/Project_Portfolio/blob/main/Images/fine-tuning_comparison.png?raw=true" style="height: 150px; width: auto;"/>
            </a>
        </td>
        <td style="text-align: center;">
            <a href="https://github.com/MattPickard/Project_Portfolio/tree/main/Fine-Tuning_for_Digit_Recognition_Project">
                <img src="https://github.com/MattPickard/Project_Portfolio/blob/main/Images/LoRa_Strength.png?raw=true" style="height: 150px; width: auto;"/>
            </a>
        </td>
    </tr>
</table>

This project tackles a fundamental challenge in machine learning: how to efficiently adapt pre-trained models to new data without compromising performance on previously learned tasks. Using hand-written digit recognition as a case study, I implemented and compared three distinct fine-tuning approaches—Experience Replay, Sequential Fine-tuning, and Low-Rank Adaptation (LoRA). This work demonstrates practical solutions to common machine learning challenges, such as adapting models when original training data is unavailable or when computational resources are limited.
